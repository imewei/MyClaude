# Machine Learning Plugin

Advanced machine learning and MLOps with **production-ready pipelines**, **multi-agent orchestration**, **comprehensive experiment tracking**, and **enterprise data infrastructure**. v1.0.3 adds execution modes, data-engineer agent, and extensive MLOps documentation.

**Version:** 1.0.7 | **Category:** ai-ml | **Status:** Active

[Full Documentation â†’](https://myclaude.readthedocs.io/en/latest/plugins/machine-learning.html) | [CHANGELOG](CHANGELOG.md)

---

## What's New in v1.0.7

This release implements **Opus 4.5 optimization** with enhanced token efficiency and standardized documentation.

### Key Improvements

- **Format Standardization**: All components now include consistent YAML frontmatter with version, maturity, specialization, and description fields
- **Token Efficiency**: 40-50% line reduction through tables over prose, minimal code examples, and structured sections
- **Enhanced Discoverability**: Clear "Use when..." trigger phrases for better Claude Code activation
- **Actionable Checklists**: Task-oriented guidance for common workflows
- **Cross-Reference Tables**: Quick-reference format for delegation and integration patterns


## ðŸŽ¯ Overview

This plugin provides comprehensive ML/DS capabilities through four specialized agents and a powerful /ml-pipeline command:

- **data-engineer** - NEW in v1.0.3: Scalable data pipelines, ETL/ELT, data quality, and storage optimization
- **data-scientist** - Statistical analysis, ML modeling, and business insights with 6-phase reasoning framework
- **ml-engineer** - Production ML systems, model serving, and performance optimization
- **mlops-engineer** - ML infrastructure, CI/CD pipelines, and deployment automation

**Key Features:**
- âœ… `/ml-pipeline` command with 3 execution modes (quick/standard/enterprise)
- âœ… 17,000+ lines of external MLOps documentation (methodology, deployment, monitoring, best practices)
- âœ… Chain-of-thought reasoning frameworks for all agents
- âœ… Constitutional AI self-correction principles
- âœ… Cross-plugin integration (python-pro, kubernetes-architect, observability-engineer)
- âœ… 7 specialized skills covering statistics, ML, deep learning, data engineering, MLOps

---

## ðŸš€ What's New in v1.0.7

### NEW data-engineer Agent
Enterprise-grade data infrastructure specialist covering:
- Data ingestion (Spark, Airflow, Kafka, CDC)
- Data quality (Great Expectations, Pydantic)
- Data versioning (DVC, lakeFS, Delta Lake)
- Storage optimization (partitioning, compression, lifecycle policies)
- 2 comprehensive examples (event stream pipeline, batch ETL)

### Enhanced /ml-pipeline Command
- **3 Execution Modes**: quick (2-3 days), standard (1-2 weeks), enterprise (3-4 weeks)
- **Agent Reference Table**: Lists all 7 specialized agents with clear role mapping
- **Interactive Mode Selection**: AskUserQuestion integration for better UX
- **Cross-Plugin Support**: Graceful degradation for optional agents
- **External Documentation**: 6 comprehensive guides (~17,000 lines total)

### Comprehensive External Docs
1. **mlops-methodology.md**: Maturity model, CI/CD, experiment tracking, governance
2. **pipeline-phases.md**: Detailed implementation checklists for all 4 phases
3. **deployment-strategies.md**: Canary, blue-green, shadow, A/B testing
4. **monitoring-frameworks.md**: Drift detection, observability, cost tracking
5. **best-practices.md**: Production readiness checklist, security, testing
6. **success-criteria.md**: Quantified KPIs for data, model, ops, velocity, cost

---

## ðŸ“‹ /ml-pipeline Command

Build end-to-end production ML pipelines with multi-agent orchestration.

### Execution Modes

**Quick Mode** (2-3 days - MVP):
```bash
/ml-pipeline "customer churn prediction for subscription service"
# Select "Quick" when prompted
# Uses: data-scientist, ml-engineer, mlops-engineer
# Delivers: Basic pipeline, model training, simple deployment
```

**Standard Mode** (1-2 weeks - Production):
```bash
/ml-pipeline "recommendation system with real-time serving"
# Select "Standard" when prompted
# Uses: data-scientist, ml-engineer, python-pro, mlops-engineer, observability-engineer
# Delivers: Full pipeline, optimized code, production serving, monitoring
```

**Enterprise Mode** (3-4 weeks - Complete Platform):
```bash
/ml-pipeline "fraud detection system with real-time processing"
# Select "Enterprise" when prompted
# Uses: data-engineer, data-scientist, ml-engineer, python-pro, mlops-engineer, kubernetes-architect, observability-engineer
# Delivers: Enterprise data infrastructure, K8s orchestration, distributed training, comprehensive observability
```

### Example Outputs

The command orchestrates agents across 4 phases:
1. **Data & Requirements**: Data pipeline architecture + feature engineering specs
2. **Model Development**: Training pipeline + hyperparameter optimization + testing
3. **Production Deployment**: Model serving + CI/CD + infrastructure as code
4. **Monitoring**: Drift detection + performance monitoring + alerting + cost tracking

### External Documentation

Access comprehensive guides:
- `commands/ml-pipeline/mlops-methodology.md` - MLOps maturity model, CI/CD practices
- `commands/ml-pipeline/pipeline-phases.md` - Phase-by-phase implementation checklists
- `commands/ml-pipeline/deployment-strategies.md` - Canary, blue-green, A/B testing
- `commands/ml-pipeline/monitoring-frameworks.md` - Drift detection, observability
- `commands/ml-pipeline/best-practices.md` - Production readiness, security, testing
- `commands/ml-pipeline/success-criteria.md` - Quantified KPIs and success metrics

---

## ðŸ¤– Agents

### NEW: data-engineer (v1.0.3)

Enterprise data infrastructure specialist for production-ready data pipelines.

**Capabilities**:
- Data ingestion (batch: Spark/Airflow, streaming: Kafka/Kinesis, CDC: Debezium)
- Data quality (Great Expectations, Pydantic, Pandera)
- Data versioning (DVC, lakeFS, Delta Lake time travel)
- Storage architecture (Bronze/Silver/Gold layers, partitioning, compression)
- ETL/ELT orchestration (Airflow, Prefect, Dagster, Kubeflow)

**Chain-of-Thought Framework** (6 phases):
1. Requirements Analysis â†’ 2. Architecture Design â†’ 3. Implementation â†’ 4. Quality Assurance â†’ 5. Deployment & Operations â†’ 6. Optimization & Iteration

**Constitutional AI Principles**:
- Data Quality First, Idempotency & Reproducibility, Cost Efficiency, Observability & Debuggability, Security & Compliance

**Example Usage**:
```bash
@data-engineer Design a scalable data pipeline for ingesting customer events from Kafka,
validating quality with Great Expectations, and storing in Delta Lake partitioned by date.
```

**Few-Shot Examples**:
1. **E-commerce Event Stream** (100K events/sec, Flink, real-time, PII masking)
2. **Batch ETL for ML Features** (daily pipeline, Spark, DVC versioning, Great Expectations)

---

### data-scientist

Expert data scientist with systematic analytical reasoning and business focus.

**Core Reasoning Framework** (6 phases):
1. **Problem Analysis** - Business objectives, success metrics, constraints
2. **Data Assessment** - Quality evaluation, sample size, bias detection
3. **Methodology Selection** - Algorithm choice, validation strategy, baselines
4. **Implementation** - Feature engineering, model building, safeguards
5. **Validation** - Robustness checks, confounding factors, generalization
6. **Communication** - Actionable insights, business recommendations, monitoring

**Constitutional AI Principles** (6 quality checks):
- Statistical Rigor, Business Relevance, Transparency, Ethical Considerations, Practical Significance, Robustness

**Structured Output Format:**
- Executive Summary (business question, key finding, recommendation, impact)
- Methodology (approach, data, assumptions, limitations)
- Results (analysis, visualizations, statistical tests, robustness)
- Recommendations (actions, monitoring, next steps, timeline)

**Few-Shot Examples:**
1. **Customer Churn Analysis** - Complete ML workflow with XGBoost (ROC-AUC=0.87, precision@20%=0.43)
2. **A/B Test Analysis** - Statistical testing with frequentist & Bayesian methods (p=0.003, 99.7% confidence)
3. **Market Basket Analysis** - Association rules for cross-selling (15 rules, $120K revenue impact)

**Example Usage:**
```
@data-scientist Analyze customer churn patterns and build a predictive model
to identify at-risk customers for our retention campaign.
```

---

### ml-engineer

Expert ML engineer focused on production reliability, performance, and scalability.

**Core Reasoning Framework** (6 phases):
1. **Requirements Analysis** - Latency, throughput, scale, budget constraints
2. **System Design** - Architecture, versioning, caching, monitoring strategy
3. **Implementation** - Error handling, logging, containerization, testing
4. **Optimization** - Profiling, model optimization, batching, load testing
5. **Deployment** - Monitoring setup, canary strategy, auto-scaling configuration
6. **Operations** - Drift detection, retraining triggers, cost efficiency

**Constitutional AI Principles** (6 production safeguards):
- Reliability, Observability, Performance, Cost Efficiency, Maintainability, Security

**Structured Output Format:**
- System Architecture (diagrams, serving pattern, scale requirements, tech stack)
- Implementation Details (model serving, API design, data pipeline, monitoring)
- Performance Characteristics (latency p50/p95/p99, throughput, resources, cost)
- Operational Runbook (deployment, monitoring, troubleshooting, scaling)

**Few-Shot Examples:**
1. **Real-Time Recommendation System** - 100K req/sec, p99<50ms with ONNX quantization, dynamic batching, Redis caching
2. **Model A/B Testing Framework** - Feature flags, shadow mode, statistical analysis, gradual rollout

**Example Usage:**
```
@ml-engineer Design a real-time recommendation system that can handle
100K predictions per second with p99 latency < 50ms.
```

---

### mlops-engineer

Expert MLOps engineer specializing in infrastructure automation, cost optimization, and multi-cloud deployment.

**Core Reasoning Framework** (6 phases):
1. **Requirements Gathering** - Team size, deployment frequency, compliance needs
2. **Architecture Design** - Orchestration, registry, deployment patterns, monitoring
3. **Infrastructure Implementation** - IaC, pipelines, CI/CD, comprehensive monitoring
4. **Automation** - Training triggers, testing, auto-scaling, self-healing
5. **Security & Compliance** - Encryption, access control, audit logging, compliance
6. **Operations & Optimization** - Cost monitoring, resource optimization, efficiency

**Constitutional AI Principles** (6 infrastructure safeguards):
- Automation-First, Reproducibility, Observability, Security-by-Default, Cost-Conscious, Scalability

**Structured Output Format:**
- Platform Architecture (components, orchestration, registry, deployment workflows)
- Infrastructure Details (cloud platform, IaC, compute, storage, networking)
- Automation Workflows (training, deployment, monitoring, data pipelines)
- Security & Compliance (access control, encryption, audit, compliance frameworks)
- Cost Analysis (current spend, optimization opportunities, allocation, projected savings)

**Few-Shot Example:**
1. **Complete AWS MLOps Platform** - Kubeflow + MLflow on EKS for 15 data scientists (~$2,800/month with 70% spot instance savings)

**Example Usage:**
```
@mlops-engineer Design a complete MLOps platform on AWS with automated
training and deployment for a team of 15 data scientists.
```

---

## ðŸ› ï¸ Skills (8)

### 1. statistical-analysis-fundamentals

Comprehensive statistical workflows using scipy.stats, statsmodels, PyMC3:
- Hypothesis testing (t-tests, ANOVA, chi-square, Mann-Whitney U)
- Bayesian methods (MCMC, posterior inference, A/B testing)
- Regression analysis (OLS, logistic, time series ARIMA)
- Experimental design (power analysis, sample size calculation)
- Causal inference (DiD, propensity score matching)

**When to use:** Statistical testing, A/B test analysis, causal inference, experimental design

---

### 2. machine-learning-essentials

Core ML workflows with scikit-learn, XGBoost, LightGBM, PyTorch:
- Classical algorithms (linear/logistic regression, trees, random forests, gradient boosting)
- Model evaluation (cross-validation, ROC-AUC, precision, recall, F1)
- Hyperparameter tuning (GridSearchCV, RandomSearchCV, Optuna, Bayesian optimization)
- Handling imbalanced data (SMOTE, class weights, undersampling)
- Model interpretability (SHAP, LIME, feature importance)
- Model deployment (FastAPI, joblib, pickle serialization)

**When to use:** Building predictive models, classification/regression tasks, model selection

---

### 3. data-wrangling-communication

Data preparation and visualization workflows:
- Data wrangling (pandas, NumPy, missing values, outliers, transformations)
- Feature engineering (encoding, scaling, time series features, polynomial features)
- Visualization (matplotlib, seaborn, plotly, interactive dashboards)
- Business communication (Streamlit, Jupyter widgets, storytelling frameworks)

**When to use:** Data cleaning, EDA, feature engineering, creating dashboards

---

### 4. advanced-ml-systems

Deep learning systems with PyTorch 2.x, TensorFlow 2.x:
- Neural architectures (CNNs, RNNs, Transformers, GANs, VAEs)
- Distributed training (PyTorch DDP, FSDP, DeepSpeed, Horovod)
- Model optimization (quantization, pruning, distillation, knowledge distillation)
- Transfer learning (fine-tuning, Hugging Face Transformers)
- Hyperparameter optimization (Optuna, Ray Tune, W&B sweeps)

**When to use:** Deep learning projects, distributed training, model optimization

---

### 5. ml-engineering-production

Production ML engineering best practices:
- Software engineering (Python type hints, pytest testing, project structure)
- Data engineering (ETL pipelines, SQL integration, Parquet optimization)
- Code quality (version control, pre-commit hooks, linting, formatting)
- Experiment tracking (MLflow, W&B, Neptune, ClearML)
- Collaboration (code reviews, documentation, pair programming)

**When to use:** Production ML code, testing strategies, data pipelines, code quality

---

### 6. model-deployment-serving

End-to-end model deployment and serving:
- Serving frameworks (FastAPI, TorchServe, BentoML, Seldon Core)
- Containerization (Docker, docker-compose, multi-stage builds)
- Kubernetes orchestration (deployments, services, ingress, auto-scaling)
- Cloud platforms (AWS SageMaker, GCP Vertex AI, Azure ML)
- Monitoring (Prometheus, Grafana, drift detection, A/B testing)

**When to use:** Model serving, API development, cloud deployment, monitoring

---

### 7. devops-ml-infrastructure

DevOps and ML infrastructure automation:
- CI/CD pipelines (GitHub Actions, GitLab CI, automated training/testing/deployment)
- Infrastructure as Code (Terraform, CloudFormation, AWS/Azure/GCP provisioning)
- Inference optimization (dynamic batching, caching, PyTorch compilation)
- Deployment automation (canary deployments, blue-green, load testing)

**When to use:** CI/CD setup, infrastructure automation, deployment strategies

---

### 8. ml-pipeline-workflow

ML pipeline orchestration and workflow automation:
- Orchestration tools (Airflow DAGs, Kubeflow Pipelines, Dagster, Prefect)
- Data validation (Great Expectations, TFX Data Validation)
- Feature engineering pipelines (automated transformations, feature stores)
- Model validation (performance testing, drift detection, A/B testing)
- Deployment strategies (canary, blue-green, shadow deployments)

**When to use:** ML pipelines, workflow orchestration, automated retraining

---

## ðŸ“Š Performance Improvements

Based on prompt engineering enhancements in v1.0.1:

| Metric | data-scientist | ml-engineer | mlops-engineer |
|--------|---------------|-------------|----------------|
| **Task Completion Quality** | +35-50% | +40-50% | +45-55% |
| **Primary Outcome** | Business insight clarity (+40-50%) | System reliability (+40-50%) | Infrastructure automation (+50-60%) |
| **Secondary Outcome** | Statistical rigor (+30-40%) | Performance optimization (+60-70%) | Cost optimization (+40-50%) |
| **Reproducibility** | +50-60% | +45-55% | +55-65% |

**Key Drivers:**
- Chain-of-thought frameworks reduce logical errors by 30-40%
- Constitutional AI self-checks catch mistakes before output (25-35% quality improvement)
- Structured templates ensure completeness (50-60% reproducibility boost)
- Few-shot examples accelerate implementation (40-50% faster task completion)

---

## ðŸš€ Quick Start

### 1. Install & Enable Plugin

```bash
# Clone the plugin (if not already installed)
git clone <repo-url> ~/.claude/plugins/machine-learning

# Enable in Claude Code settings
claude plugins enable machine-learning
```

### 2. Use an Agent

```bash
# Activate data-scientist agent
@data-scientist

# Example prompt:
"Analyze this customer dataset for churn prediction. Build a model
that identifies the top 20% of at-risk customers with high precision."
```

### 3. Leverage Skills

Skills are automatically activated based on file context:

- Working on `.py` with pandas? â†’ `data-wrangling-communication` activates
- Writing ML training code? â†’ `machine-learning-essentials` activates
- Creating Terraform files? â†’ `devops-ml-infrastructure` activates
- Building inference APIs? â†’ `model-deployment-serving` activates

### 4. Example Workflows

#### Data Science Workflow
```
@data-scientist

1. Analyze customer_data.csv for churn patterns
2. Build a predictive model with >85% ROC-AUC
3. Identify top 20% at-risk customers for retention campaign
4. Provide business recommendations with expected ROI
```

#### ML Engineering Workflow
```
@ml-engineer

1. Design a real-time product recommendation API
2. Target: 10K req/sec with p99 latency < 100ms
3. Include caching, batching, and monitoring
4. Provide complete implementation with FastAPI + Redis
```

#### MLOps Workflow
```
@mlops-engineer

1. Design end-to-end MLOps platform on AWS
2. Support 10 data scientists, automated training/deployment
3. Include experiment tracking, model registry, CI/CD
4. Optimize for cost (<$5K/month infrastructure)
```

---

## ðŸ“š Documentation & Resources

### Plugin Documentation
- [CHANGELOG.md](CHANGELOG.md) - Version history and improvements
- [Full Documentation](https://myclaude.readthedocs.io/en/latest/plugins/machine-learning.html) - Comprehensive guides

### External Resources
- [PyTorch Documentation](https://pytorch.org/docs/)
- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Kubeflow Documentation](https://www.kubeflow.org/docs/)

---

## ðŸ”§ Configuration

### Agent Selection

Choose the right agent for your task:

| Task Type | Agent | Reasoning |
|-----------|-------|-----------|
| Statistical analysis, A/B testing | `@data-scientist` | Statistical rigor, business insights |
| ML model development, EDA | `@data-scientist` | Feature engineering, model selection |
| Production ML API, serving | `@ml-engineer` | Performance optimization, reliability |
| Model optimization, batching | `@ml-engineer` | Low-latency systems, cost efficiency |
| ML infrastructure, pipelines | `@mlops-engineer` | Automation, IaC, orchestration |
| CI/CD for ML, monitoring | `@mlops-engineer` | DevOps, cloud platforms, observability |

### Skill Activation

Skills activate automatically based on file context, but you can reference them explicitly:

```
@data-scientist using statistical-analysis-fundamentals

Design an A/B test for our new checkout flow. Calculate required
sample size for 80% power to detect 0.5pp conversion lift.
```

---

## ðŸ¤ Contributing

Improvements welcome! Areas for contribution:
- Additional few-shot examples for common use cases
- Enhanced reasoning frameworks for edge cases
- Integration examples with other plugins
- Performance benchmarking and validation

---

## ðŸ“ License

See main repository license.

---

## ðŸŽ¯ Roadmap

### v1.0.2 (Bug Fixes)
- [ ] Refine constitutional AI thresholds based on usage
- [ ] Optimize few-shot example selection logic
- [ ] Enhance error messages for common failures

### v1.1.0 (Minor Features)
- [ ] Additional few-shot examples (5+ per agent)
- [ ] Multi-agent collaboration workflows
- [ ] Enhanced monitoring templates (Prometheus/Grafana)
- [ ] Multi-cloud deployment examples (Azure, GCP)

### v1.2.0 (Major Features)
- [ ] AutoML integration patterns
- [ ] Real-time feature store implementations
- [ ] Shadow deployment and multi-model serving
- [ ] Cost optimization playbooks with TCO calculators

---

**Questions or Issues?** Open an issue on the [GitHub repository](https://github.com/your-repo/claude-code-plugins).

**Last Updated:** 2025-10-31 | **Version:** 1.0.7
